{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "id": "59aOp7wc0Oh1"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T01:28:19.062550Z",
          "iopub.status.busy": "2025-03-08T01:28:19.062002Z",
          "iopub.status.idle": "2025-03-08T01:28:19.067980Z",
          "shell.execute_reply": "2025-03-08T01:28:19.066527Z",
          "shell.execute_reply.started": "2025-03-08T01:28:19.062510Z"
        },
        "trusted": true,
        "id": "HmAPpR4b0Oh3"
      },
      "outputs": [],
      "source": [
        "#importing library\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-02T20:58:30.428350Z",
          "iopub.status.busy": "2025-03-02T20:58:30.427972Z",
          "iopub.status.idle": "2025-03-02T20:58:30.433307Z",
          "shell.execute_reply": "2025-03-02T20:58:30.431787Z",
          "shell.execute_reply.started": "2025-03-02T20:58:30.428322Z"
        },
        "trusted": true,
        "id": "h2VfAj960Oh4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# # Paths\n",
        "# original_dataset_path = \"/kaggle/input/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/train\"\n",
        "\n",
        "# file_count = sum(len(files) for _, _, files in os.walk(original_dataset_path))\n",
        "\n",
        "# print(f\"Total number of training files: {file_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T01:28:25.733926Z",
          "iopub.status.busy": "2025-03-08T01:28:25.733540Z",
          "iopub.status.idle": "2025-03-08T01:28:27.699229Z",
          "shell.execute_reply": "2025-03-08T01:28:27.698015Z",
          "shell.execute_reply.started": "2025-03-08T01:28:25.733897Z"
        },
        "trusted": true,
        "id": "_1uVM6yD0Oh4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Paths to given ooriginal dataset and the one we will derive the only we need from dataset\n",
        "original_dataset_path = \"/kaggle/input/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/train\"\n",
        "new_dataset_path = \"/kaggle/working/Choosen_ILSVRC\"\n",
        "\n",
        "# Checking new dataset directories exist\n",
        "os.makedirs(f\"{new_dataset_path}/train\", exist_ok=True)\n",
        "os.makedirs(f\"{new_dataset_path}/test\", exist_ok=True)\n",
        "os.makedirs(f\"{new_dataset_path}/val\", exist_ok=True)\n",
        "\n",
        "# Selecting 100 classes\n",
        "all_classes = sorted(os.listdir(original_dataset_path))\n",
        "\n",
        "# Randomly choosing 100 classes\n",
        "selected_classes = random.sample(all_classes, 100)\n",
        "\n",
        "# Step 2: Collecting  images\n",
        "images_per_class = 500\n",
        "\n",
        "total_images = images_per_class * len(selected_classes) #100*500==500000 total images\n",
        "all_images = [] #list to store image paths.\n",
        "\n",
        "for class_name in selected_classes:\n",
        "    class_path = os.path.join(original_dataset_path, class_name)\n",
        "    images = sorted(os.listdir(class_path))[:images_per_class]  # Check 500 per class\n",
        "    all_images.extend([(class_name, img) for img in images])\n",
        "\n",
        "# To ensure random distribution of all images we collected\n",
        "random.shuffle(all_images)\n",
        "\n",
        "# Step 3: Split dataset\n",
        "train_split = 30000\n",
        "test_split = 10000\n",
        "val_split = 10000\n",
        "\n",
        "train_images = all_images[:train_split]\n",
        "test_images = all_images[train_split:train_split + test_split]\n",
        "val_images = all_images[train_split + test_split:]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T01:28:33.257944Z",
          "iopub.status.busy": "2025-03-08T01:28:33.257524Z",
          "iopub.status.idle": "2025-03-08T01:28:33.264346Z",
          "shell.execute_reply": "2025-03-08T01:28:33.262927Z",
          "shell.execute_reply.started": "2025-03-08T01:28:33.257914Z"
        },
        "trusted": true,
        "id": "Ano0SV7O0Oh4"
      },
      "outputs": [],
      "source": [
        "# Function to copy images to respective folders\n",
        "def copy_images(image_list, folder_name):\n",
        "    for class_name, img in image_list:\n",
        "        src_path = os.path.join(original_dataset_path, class_name, img)\n",
        "        dest_dir = os.path.join(new_dataset_path, folder_name, class_name)\n",
        "        os.makedirs(dest_dir, exist_ok=True)\n",
        "        shutil.copy(src_path, dest_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T01:28:43.259577Z",
          "iopub.status.busy": "2025-03-08T01:28:43.259152Z",
          "iopub.status.idle": "2025-03-08T01:33:31.340760Z",
          "shell.execute_reply": "2025-03-08T01:33:31.338717Z",
          "shell.execute_reply.started": "2025-03-08T01:28:43.259545Z"
        },
        "trusted": true,
        "id": "UlCL5xEL0Oh4",
        "outputId": "d0cb84e7-bc52-4cad-8aec-bc36a74def6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train folder is successfully created and saved.\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Save to new directories\n",
        "copy_images(train_images, \"train\")\n",
        "print(\"train folder is successfully created and saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T01:33:31.343968Z",
          "iopub.status.busy": "2025-03-08T01:33:31.343392Z",
          "iopub.status.idle": "2025-03-08T01:35:07.897113Z",
          "shell.execute_reply": "2025-03-08T01:35:07.895907Z",
          "shell.execute_reply.started": "2025-03-08T01:33:31.343917Z"
        },
        "trusted": true,
        "id": "wnSL9kYS0Oh5",
        "outputId": "7193dba4-ee44-4531-8863-ea1fb73d42b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test is successfully created and saved.\n"
          ]
        }
      ],
      "source": [
        "copy_images(test_images, \"test\")\n",
        "print(\"test is successfully created and saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T01:35:07.899610Z",
          "iopub.status.busy": "2025-03-08T01:35:07.899187Z",
          "iopub.status.idle": "2025-03-08T01:36:42.832884Z",
          "shell.execute_reply": "2025-03-08T01:36:42.831154Z",
          "shell.execute_reply.started": "2025-03-08T01:35:07.899578Z"
        },
        "trusted": true,
        "id": "uOcOsaoi0Oh5",
        "outputId": "c6108db0-ad9f-4dfa-ec31-0a7f3b8513f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val is successfully created and saved.\n"
          ]
        }
      ],
      "source": [
        "copy_images(val_images, \"val\")\n",
        "print(\"val is successfully created and saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T01:36:42.835690Z",
          "iopub.status.busy": "2025-03-08T01:36:42.835144Z",
          "iopub.status.idle": "2025-03-08T01:36:42.843310Z",
          "shell.execute_reply": "2025-03-08T01:36:42.841515Z",
          "shell.execute_reply.started": "2025-03-08T01:36:42.835642Z"
        },
        "trusted": true,
        "id": "wtqQ7jku0Oh5",
        "outputId": "3621cb46-d654-49df-f228-af7583cd41ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finally, Dataset is successfully created and saved.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Finally, Dataset is successfully created and saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T01:36:42.845506Z",
          "iopub.status.busy": "2025-03-08T01:36:42.844959Z",
          "iopub.status.idle": "2025-03-08T01:36:42.903342Z",
          "shell.execute_reply": "2025-03-08T01:36:42.901925Z",
          "shell.execute_reply.started": "2025-03-08T01:36:42.845460Z"
        },
        "trusted": true,
        "id": "EJIg6Sag0Oh5",
        "outputId": "ecf672ed-7880-4a80-a0b1-becd7d710211"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training images: 30000\n",
            "Testing images: 10000\n",
            "Validation images: 10000\n",
            "Total images: 50000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Function to count images in a directory\n",
        "def count_images(folder_path):\n",
        "    total_images = 0\n",
        "    for class_folder in os.listdir(folder_path):\n",
        "        class_path = os.path.join(folder_path, class_folder)\n",
        "        if os.path.isdir(class_path):\n",
        "            total_images += len(os.listdir(class_path))\n",
        "    return total_images\n",
        "\n",
        "# Count images in each dataset split\n",
        "train_count = count_images(os.path.join(new_dataset_path, \"train\"))\n",
        "test_count = count_images(os.path.join(new_dataset_path, \"test\"))\n",
        "val_count = count_images(os.path.join(new_dataset_path, \"val\"))\n",
        "\n",
        "# Print results\n",
        "print(f\"Training images: {train_count}\")\n",
        "print(f\"Testing images: {test_count}\")\n",
        "print(f\"Validation images: {val_count}\")\n",
        "print(f\"Total images: {train_count + test_count + val_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T01:36:42.905052Z",
          "iopub.status.busy": "2025-03-08T01:36:42.904747Z",
          "iopub.status.idle": "2025-03-08T01:36:42.912345Z",
          "shell.execute_reply": "2025-03-08T01:36:42.910642Z",
          "shell.execute_reply.started": "2025-03-08T01:36:42.905027Z"
        },
        "trusted": true,
        "id": "lnalju2Y0Oh6"
      },
      "outputs": [],
      "source": [
        "# Check number of classes\n",
        "def count_classes(folder_path):\n",
        "    return len([d for d in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, d))])\n",
        "\n",
        "# Check number of images in each class\n",
        "def count_images_per_class(folder_path):\n",
        "    class_counts = {}\n",
        "    for class_folder in os.listdir(folder_path):\n",
        "        class_path = os.path.join(folder_path, class_folder)\n",
        "        if os.path.isdir(class_path):\n",
        "            class_counts[class_folder] = len(os.listdir(class_path))\n",
        "    return class_counts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T01:36:42.914527Z",
          "iopub.status.busy": "2025-03-08T01:36:42.914078Z",
          "iopub.status.idle": "2025-03-08T01:36:42.934896Z",
          "shell.execute_reply": "2025-03-08T01:36:42.933460Z",
          "shell.execute_reply.started": "2025-03-08T01:36:42.914491Z"
        },
        "trusted": true,
        "id": "hzSh38Jb0Oh6",
        "outputId": "126ab063-e378-477c-fd52-1c6f184e42ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total classes in train: 100\n",
            "Total classes in test: 100\n",
            "Total classes in val: 100\n"
          ]
        }
      ],
      "source": [
        "#COUNT CLASSES IN EACH FOLDER WE SEPARATED\n",
        "train_classes = count_classes(os.path.join(new_dataset_path, \"train\"))\n",
        "test_classes = count_classes(os.path.join(new_dataset_path, \"test\"))\n",
        "val_classes = count_classes(os.path.join(new_dataset_path, \"val\"))\n",
        "\n",
        "print(f\"Total classes in train: {train_classes}\")\n",
        "print(f\"Total classes in test: {test_classes}\")\n",
        "print(f\"Total classes in val: {val_classes}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T01:36:42.938389Z",
          "iopub.status.busy": "2025-03-08T01:36:42.937976Z",
          "iopub.status.idle": "2025-03-08T01:36:42.992579Z",
          "shell.execute_reply": "2025-03-08T01:36:42.991276Z",
          "shell.execute_reply.started": "2025-03-08T01:36:42.938357Z"
        },
        "trusted": true,
        "id": "rgD4VXhL0Oh6",
        "outputId": "4aae86f9-ec1f-4b36-cec9-578d216116dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total images in train: 30000\n",
            "Total images in test: 10000\n",
            "Total images in val: 10000\n"
          ]
        }
      ],
      "source": [
        "# Count total images in each split\n",
        "train_images = count_images_per_class(os.path.join(new_dataset_path, \"train\"))\n",
        "test_images = count_images_per_class(os.path.join(new_dataset_path, \"test\"))\n",
        "val_images = count_images_per_class(os.path.join(new_dataset_path, \"val\"))\n",
        "\n",
        "print(f\"Total images in train: {sum(train_images.values())}\")\n",
        "print(f\"Total images in test: {sum(test_images.values())}\")\n",
        "print(f\"Total images in val: {sum(val_images.values())}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T02:17:25.446282Z",
          "iopub.status.busy": "2025-03-08T02:17:25.445852Z",
          "iopub.status.idle": "2025-03-08T02:17:29.248502Z",
          "shell.execute_reply": "2025-03-08T02:17:29.246686Z",
          "shell.execute_reply.started": "2025-03-08T02:17:25.446248Z"
        },
        "trusted": true,
        "id": "0KMjDGmt0Oh7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define dataset paths\n",
        "dataset_path = \"/kaggle/working/Choosen_ILSVRC\"\n",
        "\n",
        "# ImageNet standard input size for AlexNet\n",
        "IMG_SIZE = 224  # AlexNet expects 224x224 input size\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# ImageNet mean and standard deviation for normalization\n",
        "IMAGENET_MEAN = tf.constant([0.485, 0.456, 0.406])\n",
        "IMAGENET_STD = tf.constant([0.229, 0.224, 0.225])\n",
        "\n",
        "def preprocess_image(image, label, training=True):\n",
        "    if tf.shape(image)[-1] == 1:\n",
        "        image = tf.image.grayscale_to_rgb(image)\n",
        "    elif tf.shape(image)[-1] == 4:\n",
        "        image = image[:, :, :3]\n",
        "\n",
        "    # Resize image to 256x256\n",
        "    image = tf.image.resize_with_pad(image, 256, 256)\n",
        "\n",
        "    if training:\n",
        "        image = tf.image.random_crop(image, (224, 224, 3))\n",
        "        image = tf.image.random_flip_left_right(image)\n",
        "    else:\n",
        "        image = tf.image.central_crop(image, central_fraction=0.875)\n",
        "\n",
        "    # Normalize\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    image = (image - IMAGENET_MEAN) / IMAGENET_STD\n",
        "\n",
        "    return image, label\n",
        "\n",
        "\n",
        "# Load datasets using TensorFlow's image_dataset_from_directory\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataset_path + \"/train\",\n",
        "    label_mode=\"int\",\n",
        "    image_size=(256, 256),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataset_path + \"/val\",\n",
        "    label_mode=\"int\",\n",
        "    image_size=(256, 256),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataset_path + \"/test\",\n",
        "    label_mode=\"int\",\n",
        "    image_size=(256, 256),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "train_ds = train_ds.map(lambda x, y: preprocess_image(x, y, training=True), num_parallel_calls=tf.data.AUTOTUNE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(lambda x, y: preprocess_image(x, y, training=False), num_parallel_calls=tf.data.AUTOTUNE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.map(lambda x, y: preprocess_image(x, y, training=False), num_parallel_calls=tf.data.AUTOTUNE).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T02:19:40.918737Z",
          "iopub.status.busy": "2025-03-08T02:19:40.918206Z",
          "iopub.status.idle": "2025-03-08T02:19:40.930384Z",
          "shell.execute_reply": "2025-03-08T02:19:40.929087Z",
          "shell.execute_reply.started": "2025-03-08T02:19:40.918701Z"
        },
        "trusted": true,
        "id": "ssp4ld5m0Oh7",
        "outputId": "d04584f2-ffc0-4f6d-9280-6826a654e7c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set: 235 batches\n",
            "Validation set: 79 batches\n",
            "Testing set: 79 batches\n"
          ]
        }
      ],
      "source": [
        "# Check dataset structure\n",
        "print(f\"Training set: {len(train_ds)} batches\")\n",
        "print(f\"Validation set: {len(val_ds)} batches\")\n",
        "print(f\"Testing set: {len(test_ds)} batches\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "17nuqZ2Y0Oh7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 4225553,
          "sourceId": 6799,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30918,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}